import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, callbacks
from tensorflow.keras.mixed_precision import set_global_policy
import concurrent.futures
from tqdm import tqdm
from datetime import datetime

set_global_policy('mixed_float16')

tf.config.threading.set_intra_op_parallelism_threads(12)
tf.config.threading.set_inter_op_parallelism_threads(12)

dataset = pd.read_csv("LST_final_TRUE.csv")
features = ["H", "TWI", "Aspect", "Hillshade", "Roughness", "Slope",
            "Temperature_merra_1000hpa", "Time", "DayOfYear", "X", "Y"]
target = "T_rp5"

X = dataset[features].values
y = dataset[target].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

epochs_options = [100, 150]
batch_size_options = [32, 64]
neurons_options = [(128, 64, 32), (256, 128, 64)]
activation_options = ['relu', 'elu']
dropout_options = [0.0, 0.3]
learning_rate_options = [0.001, 0.0005]
batch_norm_options = [True, False]

log_dir_base = "tensorboard_logs"
os.makedirs(log_dir_base, exist_ok=True)

def run_model(epochs, batch_size, neurons, activation, dropout_rate, learning_rate, batch_norm):
    model = keras.Sequential()

    for i, units in enumerate(neurons):
        model.add(layers.Dense(units, activation=activation))
        if batch_norm:
            model.add(layers.BatchNormalization())
        if dropout_rate > 0:
            model.add(layers.Dropout(dropout_rate))

    model.add(layers.Dense(1))

    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss="mse", metrics=["mae"])

    log_dir = os.path.join(log_dir_base, datetime.now().strftime("%Y%m%d-%H%M%S"))
    tensorboard_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
    early_stop_cb = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),
                        epochs=epochs, batch_size=batch_size,
                        callbacks=[early_stop_cb, tensorboard_cb],
                        verbose=0)

    predictions = model.predict(X_test)
    mse = mean_squared_error(y_test, predictions)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, predictions)
    mape = mean_absolute_percentage_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)

    return mse, rmse, mae, mape, r2

results = []
param_combinations = [(e, b, n, a, d, l, bn)
                      for e in epochs_options
                      for b in batch_size_options
                      for n in neurons_options
                      for a in activation_options
                      for d in dropout_options
                      for l in learning_rate_options
                      for bn in batch_norm_options]

def process_combination(params):
    e, b, n, a, d, l, bn = params
    metrics = run_model(e, b, n, a, d, l, bn)
    return (e, b, n, a, d, l, bn, *metrics)

with concurrent.futures.ThreadPoolExecutor() as executor:
    futures = [executor.submit(process_combination, params) for params in param_combinations]
    for f in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):
        results.append(f.result())

df_results = pd.DataFrame(results, columns=["Epochs", "Batch Size", "Neurons", "Activation",
                                            "Dropout", "Learning Rate", "BatchNorm",
                                            "MSE", "RMSE", "MAE", "MAPE", "R¬≤"])
df_results.sort_values(by="MSE", inplace=True)
df_results.to_csv("optimized_mlp_results.csv", index=False)

metrics = ["MSE", "RMSE", "MAE", "MAPE", "R¬≤"]
fig, axs = plt.subplots(3, 2, figsize=(14, 12))
axs = axs.flatten()
for i, metric in enumerate(metrics):
    sns.boxplot(x="Activation", y=metric, data=df_results, ax=axs[i])
    axs[i].set_title(f"{metric} by Activation")
axs[-1].axis('off')
plt.tight_layout()
plt.show()


    # ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
    # 1. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ThreadPoolExecutor –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–µ—Ä–µ–±–æ—Ä–∞, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –æ–±—â–µ–µ –≤—Ä–µ–º—è –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ CPU.
    #
    # 2. –ü–æ–¥–¥–µ—Ä–∂–∫–∞ GPU –∏ mixed precision
    # –í–∫–ª—é—á–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ mixed_float16, —á—Ç–æ —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ GPU (–æ—Å–æ–±–µ–Ω–Ω–æ RTX 4060), —Å–Ω–∏–∂–∞—è –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ —É–≤–µ–ª–∏—á–∏–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–π —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏.
    #
    # 3. –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫
    # –í—ã–≤–æ–¥—è—Ç—Å—è 5 –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ (MSE, RMSE, MAE, MAPE, R¬≤), —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–µ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –º–æ–¥–µ–ª—å –∏ –Ω–µ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ MSE.
    #
    # 4. EarlyStopping –∏ BatchNormalization
    # EarlyStopping –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ —ç–∫–æ–Ω–æ–º–∏—Ç –≤—Ä–µ–º—è.
    #
    # BatchNormalization —É—Å–∫–æ—Ä—è–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∏ –¥–µ–ª–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–º.
    #
    # 5. TensorBoard –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
    # –ü–æ–¥–∫–ª—é—á—ë–Ω TensorBoard –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ª–æ—Å—Å–∞, –º–µ—Ç—Ä–∏–∫, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤.
    #
    # 6. –ì–∏–±–∫–∏–π –∏ —Ä–∞—Å—à–∏—Ä—è–µ–º—ã–π –∫–æ–¥
    # –ö–æ–¥ –ª–µ–≥–∫–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç—Å—è: –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ —Å–ª–æ–∏, –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –º–µ—Ç—Ä–∏–∫–∏ –∏ –ø—Ä.
    #
    # ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
    # 1. –ë–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    # –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å, –ø–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 128+) –∑–∞–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (–¥–æ –¥–µ—Å—è—Ç–∫–æ–≤ —á–∞—Å–æ–≤) ‚Äî –æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–∏ –Ω–µ–±–æ–ª—å—à–æ–º —É—Å–∫–æ—Ä–µ–Ω–∏–∏ –Ω–∞ CPU.
    #
    # 2. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ThreadPoolExecutor, –∞ –Ω–µ ProcessPoolExecutor
    # –≠—Ç–æ –º–æ–∂–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∏ —Ç—è–∂—ë–ª—ã—Ö –∑–∞–¥–∞—á–∞—Ö –æ–±—É—á–µ–Ω–∏—è, –ø–æ—Å–∫–æ–ª—å–∫—É –ø–æ—Ç–æ–∫–∏ –¥–µ–ª—è—Ç –ø–∞–º—è—Ç—å –∏ —Ä–µ—Å—É—Ä—Å—ã (–≤–º–µ—Å—Ç–æ –∑–∞–ø—É—Å–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤).
    #
    # 3. –ù–µ—Ç —É–º–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (GridSearch —Ç–æ–ª—å–∫–æ)
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä (grid search), –∞ –Ω–µ random search –∏–ª–∏ optuna, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç –±—ã—Å—Ç—Ä–µ–µ –∏ —á–∞—Å—Ç–æ –¥–∞—é—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
    #
    # 4. –ù–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∏–ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–≥—Ä—É–∑–∫–∏
    # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∑–∫–µ CPU/GPU, —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
    #
    # üí° –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    # –î–∞–Ω–Ω—ã–π –∫–æ–¥ ‚Äî —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏ –≥–∏–±–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ MLP —Å —É–ø–æ—Ä–æ–º –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å, —Ä–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å –∏ —Ö–æ—Ä–æ—à—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫. –û–¥–Ω–∞–∫–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä—ë–º–∞—Ö –¥–∞–Ω–Ω—ã—Ö —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –ª—É—á—à–µ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã GPU.
    #   7%|‚ñã         | 9/128 [1:08:12<5:52:10, 177.57s/it]